{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DkE-Rv5poGK3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. What is a parameter?\n",
        "\n",
        "==A parameter is a numerical value that describes a characteristic of a population (not just a sample).\n",
        "\n",
        "Example:\n",
        "\n",
        "Population mean (μ), population standard deviation (σ).\n",
        "\n",
        "In Machine Learning, parameters can also mean the coefficients/weights of a model that are learned during training.\n",
        "\n",
        "2. What is correlation? What does negative correlation mean?\n",
        "\n",
        "==Correlation is a statistical measure that describes the strength and direction of a relationship between two variables.\n",
        "\n",
        "Range: -1 to +1\n",
        "\n",
        "+1 = Perfect positive correlation\n",
        "\n",
        "-1 = Perfect negative correlation\n",
        "\n",
        "0 = No correlation\n",
        "\n",
        "==Negative correlation means when one variable increases, the other decreases.\n",
        "\n",
        "Example: Number of hours spent watching TV  vs Exam scores  (more TV → lower marks).\n",
        "\n",
        "3. Define Machine Learning. What are the main components in Machine Learning?\n",
        "\n",
        "==Machine Learning (ML): A branch of AI where systems learn patterns from data and improve performance without being explicitly programmed.\n",
        "\n",
        " Main Components:\n",
        "\n",
        "Data → Input to the ML system.\n",
        "\n",
        "Features → Variables used for prediction.\n",
        "\n",
        "Model → Algorithm (e.g., Linear Regression, Decision Tree).\n",
        "\n",
        "Training → Process of learning model parameters from data.\n",
        "\n",
        "Evaluation → Measuring performance using test data.\n",
        "\n",
        "Prediction → Applying model to new/unseen data.\n",
        "\n",
        "\n",
        "4. How does loss value help in determining whether the model is good or not?\n",
        "\n",
        "==Loss value measures how far predictions are from actual values.\n",
        "\n",
        "Lower loss = Better model fit.\n",
        "\n",
        "Example:\n",
        "\n",
        "Mean Squared Error (MSE) for regression.\n",
        "\n",
        "Cross-Entropy Loss for classification.\n",
        "\n",
        "\n",
        "5. What are continuous and categorical variables?\n",
        "\n",
        "==continuous variable: Numerical values that can take infinitely many values.\n",
        "\n",
        "Example: Height, Temperature, Price.\n",
        "\n",
        "Categorical variable: Represents categories or groups.\n",
        "\n",
        "Example: Gender (Male/Female), City (Delhi, Mumbai, Chennai).\n",
        "\n",
        "\n",
        "\n",
        "6. How do we handle categorical variables in Machine Learning? What are the common techniques?\n",
        "\n",
        "== ML models require numerical input, so we convert categories to numbers.\n",
        "\n",
        " Common techniques:\n",
        "\n",
        "Label Encoding → Assigns each category an integer.\n",
        "\n",
        "One-Hot Encoding → Creates binary columns for each category.\n",
        "\n",
        "Ordinal Encoding → For ordered categories (e.g., Low < Medium < High).\n",
        "\n",
        "\n",
        "\n",
        "7. What do you mean by training and testing a dataset?\n",
        "==\n",
        "Training dataset: Used to teach the model (fit parameters).\n",
        "\n",
        "Testing dataset: Used to evaluate performance on unseen data.\n",
        "\n",
        "\n",
        "8. What is sklearn.preprocessing?\n",
        "==\n",
        "sklearn.preprocessing is a module in scikit-learn that provides tools for:\n",
        "\n",
        "Scaling (StandardScaler, MinMaxScaler)\n",
        "\n",
        "Encoding categorical variables (LabelEncoder, OneHotEncoder)\n",
        "\n",
        "Normalization, Polynomial features, etc.\n",
        "\n",
        "\n",
        "9. What is a Test set?\n",
        "==\n",
        "A test set is the portion of data that is kept aside to evaluate model performance.\n",
        "\n",
        "It simulates how the model will perform on unseen data.\n",
        "\n",
        "\n",
        "\n",
        "10. How do we split data for model fitting (training and testing) in Python?How do you approach a Machine Learning problem?\n",
        "\n",
        "==\n",
        "Define the problem.\n",
        "\n",
        "Collect & clean data.\n",
        "\n",
        "Perform Exploratory Data Analysis (EDA).\n",
        "\n",
        "Preprocess data (scaling, encoding, missing values).\n",
        "\n",
        "Split data into training & test sets.\n",
        "\n",
        "Choose appropriate ML model.\n",
        "\n",
        "Train the model.\n",
        "\n",
        "Evaluate with metrics (accuracy, RMSE, etc.).\n",
        "\n",
        "Tune hyperparameters.\n",
        "\n",
        "Deploy and monitor model.\n",
        "\n",
        "\n",
        "\n",
        "11. Why do we have to perform EDA before fitting a model to the data?\n",
        "==\n",
        "EDA = Exploratory Data Analysis.\n",
        "\n",
        "Helps understand patterns, outliers, and missing values.\n",
        "\n",
        "Helps choose correct preprocessing methods.\n",
        "\n",
        "Prevents garbage in → garbage out problem.\n",
        "\n",
        "\n",
        "12. What is correlation?\n",
        "==\n",
        "Correlation = statistical relationship between variables.\n",
        "\n",
        "\n",
        "13. What does negative correlation mean?\n",
        "==\n",
        "Negative correlation = when one increases, the other decreases.\n",
        "\n",
        "\n",
        "15. What is causation? Explain difference between correlation and causation with an example\n",
        "==\n",
        "\n",
        "Causation: When one variable directly influences another.\n",
        "\n",
        "Correlation: When two variables are related but not necessarily causal.\n",
        "\n",
        "Example:\n",
        "\n",
        "Ice cream sales  and drowning incidents are correlated (both increase in summer).\n",
        "\n",
        "But ice cream doesn’t cause drowning → they’re both caused by temperature.\n",
        "\n",
        "Here, correlation exists but no causation.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "16. What is an Optimizer? What are different types of optimizers? Explain each with an example.\n",
        "\n",
        "= An optimizer is an algorithm used in training machine learning models (especially deep learning) to adjust model weights in order to minimize the loss function.\n",
        "\n",
        "Types of Optimizers:\n",
        "\n",
        "1. Gradient Descent (GD)\n",
        "\n",
        "Updates weights in the direction of the negative gradient of the loss function.\n",
        "Slow for large datasets.\n",
        "\n",
        "# Formula: w = w - α * ∂L/∂w\n",
        "\n",
        "\n",
        "2. Stochastic Gradient Descent (SGD)\n",
        "\n",
        "Updates weights using one sample at a time instead of the whole dataset.\n",
        "Faster but noisier.\n",
        "\n",
        "3. Mini-Batch Gradient Descent\n",
        "Uses small batches of data for updates (trade-off between GD & SGD).\n",
        "\n",
        "4. Momentum Optimizer\n",
        "Adds a \"velocity\" term to smooth out updates (avoids zig-zagging).\n",
        "\n",
        "5. AdaGrad\n",
        "Uses different learning rates for each parameter (good for sparse data).\n",
        "\n",
        "6. RMSProp\n",
        "Fixes AdaGrad’s decreasing learning rate problem by using moving averages.\n",
        "\n",
        "7. Adam (Adaptive Moment Estimation)\n",
        "Combines Momentum + RMSProp, most widely used.\n",
        "\n",
        "\n",
        "17. What is sklearn.linear_model ?\n",
        "\n",
        "== sklearn.linear_model is a module in Scikit-learn that provides linear models like:\n",
        "LinearRegression (for regression problems)\n",
        "LogisticRegression (for classification problems)\n",
        "Ridge, Lasso, ElasticNet (regularized regression)\n",
        "\n",
        "\n",
        "18. What does model.fit() do? What arguments must be given?\n",
        "==Trains the model on the given data.\n",
        "Arguments:\n",
        "X_train → features\n",
        "y_train → target labels\n",
        "\n",
        "19. What does model.predict() do? What arguments must be given?\n",
        "==Uses the trained model to predict outcomes for new/unseen data.\n",
        "Arguments:\n",
        "X_test → features (input data only)\n",
        "\n",
        "20. What are continuous and categorical variables?\n",
        "==Continuous variables → numerical values within a range (e.g., height, weight, age, income).\n",
        "\n",
        "Categorical variables → represent categories or labels (e.g., gender = Male/Female, colors = Red/Blue)\n",
        "\n",
        "21. What is feature scaling? How does it help in Machine Learning?\n",
        "==Process of bringing all features to a similar scale.\n",
        "\n",
        "Prevents variables with larger ranges from dominating the model.\n",
        "\n",
        "Common in algorithms like KNN, SVM, Gradient Descent-based models.\n",
        "\n",
        "\n",
        "22. How do we perform scaling in Python?\n",
        "\n",
        "==Feature scaling is the process of bringing all features (independent variables) to the same scale so that no feature dominates others due to larger values.\n",
        "\n",
        " Example:\n",
        "\n",
        "Age: 25, 30, 40\n",
        "\n",
        "Income: 30,000, 80,000, 1,00,000\n",
        "\n",
        "Here, \"Income\" values are much larger than \"Age\". Many ML algorithms (like KNN, SVM, Logistic Regression) use distance or gradient-based optimization, so features with larger ranges can bias the model.\n",
        "\n",
        "23. What is sklearn.preprocessing?\n",
        "\n",
        "==A Scikit-learn module with tools for data preprocessing, including:\n",
        "\n",
        "Scaling (StandardScaler, MinMaxScaler)\n",
        "\n",
        "Encoding (OneHotEncoder, LabelEncoder)\n",
        "\n",
        "Normalization, Imputation, Binarization, Polynomial features\n",
        "\n",
        "24. How do we split data for model fitting (training and testing) in Python?\n",
        "==\n",
        "When we build a machine learning model, we want it to learn patterns from data and also generalize well to unseen data.\n",
        "If we train and test on the same dataset, the model may simply memorize it (overfitting).\n",
        "\n",
        "Common Split Ratios\n",
        "\n",
        "70% training / 30% testing (small datasets).\n",
        "\n",
        "80% training / 20% testing (large datasets).\n",
        "\n",
        "60% train / 20% validation / 20% test (when a validation set is also needed).\n",
        "\n",
        "25. Explain data encoding?\n",
        "\n",
        "==Data encoding in Machine Learning refers to the process of converting categorical (non-numeric) data into a numerical format so that algorithms can process it."
      ],
      "metadata": {
        "id": "lXHP3Qn9oJIw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#10. How do we split data for model fitting (training and testing) in Python?\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "# Example dataset\n",
        "df = pd.DataFrame({\n",
        "    \"Hours_Studied\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
        "    \"Exam_Score\":    [50, 55, 60, 65, 70, 72, 75, 80, 85, 90]\n",
        "})\n",
        "\n",
        "X = df[[\"Hours_Studied\"]]   # Features (independent variable)\n",
        "y = df[\"Exam_Score\"]        # Target (dependent variable)\n",
        "\n",
        "# Split into training (80%) and testing (20%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(\"Training Features:\\n\", X_train)\n",
        "print(\"Testing Features:\\n\", X_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBFzDNp9soau",
        "outputId": "90b815e0-7dba-4569-ec7f-728f4001c411"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Features:\n",
            "    Hours_Studied\n",
            "5              6\n",
            "0              1\n",
            "7              8\n",
            "2              3\n",
            "9             10\n",
            "4              5\n",
            "3              4\n",
            "6              7\n",
            "Testing Features:\n",
            "    Hours_Studied\n",
            "8              9\n",
            "1              2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#14. How can you find correlation between variables in Python?\n",
        "'''\n",
        "Correlation measures the strength and direction of the linear relationship between two variables.\n",
        "\n",
        "Value ranges from -1 to +1.\n",
        "\n",
        "+1 → perfect positive correlation\n",
        "\n",
        "-1 → perfect negative correlation\n",
        "\n",
        "0 → no correlation\n",
        "\n",
        "'''\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Example dataset\n",
        "data = {\n",
        "    \"Hours_Studied\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
        "    \"Exam_Score\":    [50, 55, 60, 65, 70, 72, 75, 80, 85, 90],\n",
        "    \"Sleep_Hours\":   [8, 8, 7, 7, 6, 6, 5, 5, 4, 4]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Correlation matrix\n",
        "print(df.corr())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSMSbGuxtbVZ",
        "outputId": "af00b08f-24d5-488b-dc1b-dd2927e7ed8f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               Hours_Studied  Exam_Score  Sleep_Hours\n",
            "Hours_Studied       1.000000    0.996584    -0.984732\n",
            "Exam_Score          0.996584    1.000000    -0.980320\n",
            "Sleep_Hours        -0.984732   -0.980320     1.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#How do we perform scaling in Python?\n",
        "\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, MaxAbsScaler\n",
        "\n",
        "# Sample dataset\n",
        "data = {\n",
        "    'Age': [25, 30, 35, 40, 45],\n",
        "    'Income': [30000, 50000, 70000, 100000, 120000]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "print(\"Original Data:\\n\", df)\n",
        "\n",
        "# 1. Standardization (Z-score scaling)\n",
        "scaler_standard = StandardScaler()\n",
        "df_standard = scaler_standard.fit_transform(df)\n",
        "print(\"\\nStandard Scaler:\\n\", df_standard)\n",
        "\n",
        "# 2. Min-Max Scaling (Normalization to [0,1])\n",
        "scaler_minmax = MinMaxScaler()\n",
        "df_minmax = scaler_minmax.fit_transform(df)\n",
        "print(\"\\nMin-Max Scaler:\\n\", df_minmax)\n",
        "\n",
        "# 3. Robust Scaling (handles outliers better)\n",
        "scaler_robust = RobustScaler()\n",
        "df_robust = scaler_robust.fit_transform(df)\n",
        "print(\"\\nRobust Scaler:\\n\", df_robust)\n",
        "\n",
        "# 4. MaxAbs Scaling (scales between -1 and 1)\n",
        "scaler_maxabs = MaxAbsScaler()\n",
        "df_maxabs = scaler_maxabs.fit_transform(df)\n",
        "print(\"\\nMaxAbs Scaler:\\n\", df_maxabs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJ1R1ds6xVsK",
        "outputId": "a783fc5b-48c5-4da7-c3d1-965fa3da1601"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Data:\n",
            "    Age  Income\n",
            "0   25   30000\n",
            "1   30   50000\n",
            "2   35   70000\n",
            "3   40  100000\n",
            "4   45  120000\n",
            "\n",
            "Standard Scaler:\n",
            " [[-1.41421356 -1.34890655]\n",
            " [-0.70710678 -0.73576721]\n",
            " [ 0.         -0.12262787]\n",
            " [ 0.70710678  0.79708114]\n",
            " [ 1.41421356  1.41022048]]\n",
            "\n",
            "Min-Max Scaler:\n",
            " [[0.         0.        ]\n",
            " [0.25       0.22222222]\n",
            " [0.5        0.44444444]\n",
            " [0.75       0.77777778]\n",
            " [1.         1.        ]]\n",
            "\n",
            "Robust Scaler:\n",
            " [[-1.  -0.8]\n",
            " [-0.5 -0.4]\n",
            " [ 0.   0. ]\n",
            " [ 0.5  0.6]\n",
            " [ 1.   1. ]]\n",
            "\n",
            "MaxAbs Scaler:\n",
            " [[0.55555556 0.25      ]\n",
            " [0.66666667 0.41666667]\n",
            " [0.77777778 0.58333333]\n",
            " [0.88888889 0.83333333]\n",
            " [1.         1.        ]]\n"
          ]
        }
      ]
    }
  ]
}